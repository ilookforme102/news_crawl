{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb830eea-57ed-4e6d-8151-83a5ceec8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup,NavigableString, Comment\n",
    "import lxml\n",
    "def convert_string(input_str):\n",
    "    # Regular expression pattern to match a date in the format dd-mm-yyyy\n",
    "    pattern =r'\\d+/\\d+/\\d+'\n",
    "    \n",
    "    # Search for the pattern in the string\n",
    "    match = re.search(pattern, input_str)\n",
    "    if match:\n",
    "    # Extract and print the date if found\n",
    "        date_str = match.group(0)\n",
    "        date_obj = datetime.strptime(date_str, '%d/%m/%Y')\n",
    "        date_str = date_obj.strftime('%Y-%m-%d')\n",
    "        return date_str,date_obj\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_datetime_obj(string):\n",
    "\n",
    "    # Regular expression pattern to match the date\n",
    "    pattern = r'\\d{2}/\\d{2}/\\d{4}'\n",
    "    \n",
    "    # Search for the pattern in the string and extract the date\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        date_str = match.group(0)\n",
    "        # Convert the extracted date string to datetime object\n",
    "        date_obj = datetime.strptime(date_str, '%d/%m/%Y')\n",
    "        date_str = date_obj.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        date_obj = None\n",
    "        date_str = None\n",
    "    \n",
    "    return date_obj,date_str\n",
    "def get_content_vtv(url):\n",
    "    response = requests.get(url)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.find('h1').text.strip()\n",
    "    date = soup.find('p', class_ = 'news-info').text.strip()\n",
    "    published_date = get_datetime_obj(date)[1]\n",
    "    first_paragraph = soup.find('h2', class_  = 'sapo')\n",
    "    article = soup.find('div', id = 'entry-body')\n",
    "    #strong_tag = soup.new_tag('strong') \n",
    "    #strong_tag.string = first_paragraph.text # Set the content of <i> tag\n",
    "    # Insert the new element as the first child\n",
    "    article.insert(0, first_paragraph)\n",
    "    \n",
    "    for script_or_style in article(['script', 'style','iframe','video',]):\n",
    "                script_or_style.decompose()\n",
    "    \n",
    "    caption_text_list = article.find_all('div', class_ ='PhotoCMS_Caption')\n",
    "    tags_to_remove = article.find_all(['a', 'span'])\n",
    "    for tag in tags_to_remove:\n",
    "        # Extract the text from the tag\n",
    "        tag_text = tag.get_text()\n",
    "        # Replace the tag with its text content\n",
    "        tag.replace_with(tag_text)\n",
    "        tag.text.strip()\n",
    "    #remove all image attributes except somes from list\n",
    "    list_attr = ['src','alt','data-original']\n",
    "    for i in article.find_all('img'):\n",
    "        for j in list(i.attrs.keys()):\n",
    "            if j not in list_attr:\n",
    "                i.attrs.pop(j)\n",
    "    img_list = article.find_all('img')\n",
    "    n_img = len(img_list)\n",
    "    for i in range(0,n_img):\n",
    "           \n",
    "        caption_start = NavigableString(\"[caption id=\\\"\\\" align=\\\"aligncenter\\\" width=\\\"800\\\"]\")\n",
    "        try:\n",
    "            caption_text = NavigableString(caption_text_list[i].find('p').get_text())\n",
    "        except (IndexError,AttributeError):\n",
    "            continue\n",
    "        caption_end = NavigableString(\"[/caption]\")\n",
    "        # Insert the custom tags and caption text around the <img> tag\n",
    "        img_list[i].insert_before(caption_start)\n",
    "        img_list[i].insert_after(caption_end)\n",
    "        img_list[i].insert_after(caption_text) \n",
    "    for i in article.find_all('img'):\n",
    "        try:\n",
    "            i['src'] = i['data-src']\n",
    "        except KeyError:\n",
    "            continue\n",
    "    for i in caption_text_list:\n",
    "        i.decompose()\n",
    "    # add avatar photo on top\n",
    "    first_photo = soup.find('img', class_ = 'news-avatar')\n",
    "    try:\n",
    "        article.insert(0, first_photo)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    # centering the image\n",
    "    for i in article.find_all('img'):\n",
    "        i['class'] = \"aligncenter\"\n",
    "        #i['width'] = 800\n",
    "       # i['height'] = 400\n",
    "        del i['data-src']\n",
    "    list_attr = ['src','alt','data-ogiginal','class']\n",
    "    for i in article.find_all(recursive = True):\n",
    "        for j in list(i.attrs.keys()):\n",
    "            if j not in list_attr:\n",
    "                i.attrs.pop(j)\n",
    "    #remove empty div or empty space from element\n",
    "    for item in article.find_all('div'):\n",
    "        if item.string ==\"\":\n",
    "            item.decompose()\n",
    "    for element in article.find_all(recursive = True,string=True):\n",
    "        if isinstance(element, NavigableString) and element.strip() == '':\n",
    "            element.extract()\n",
    "    #remove html comment from element   \n",
    "    article.find_all('p',recursive = True)[-1].decompose()\n",
    "    for comment in article.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "    \n",
    "    #article.find_all(recursive = True)[-1].decompose()\n",
    "    #article.find('div', class_ ='width_common box-tinlienquanv2').decompose()\n",
    "    source_tag = soup.new_tag('i') \n",
    "    source_tag.string = \"Nguồn: vtv.vn\"  # Set the content of <i> tag\n",
    "    article.append(source_tag)\n",
    "    return article, title, published_date\n",
    "def get_post(url):\n",
    "    try:\n",
    "        content,title,published_date = get_content_vtv(url)\n",
    "        return content,title,published_date\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "def get_list_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    items = soup.find_all('h3')\n",
    "    urls = []\n",
    "    for i in items:\n",
    "        path = i.find('a')['href']\n",
    "        url = 'https://vtv.vn/'+ path\n",
    "        urls.append(url)\n",
    "    return urls\n",
    "def filter_list(urls):\n",
    "    filtered_urls = []\n",
    "    crawl_time = datetime.fromtimestamp(time.time()-1*24*3600)\n",
    "    for i in range(0,len(urls)):\n",
    "        try:\n",
    "            published_date = get_content_vtv(urls[i])[2]\n",
    "            date_posted_norm = datetime.strptime(published_date, '%Y-%m-%d')\n",
    "            if ( (date_posted_norm.day == crawl_time.day) and (date_posted_norm.month == crawl_time.month) and (date_posted_norm.year == crawl_time.year) ):\n",
    "                filtered_urls.append(urls[i])\n",
    "                #print(i)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return filtered_urls\n",
    "#add list url to json\n",
    "#add list url to json\n",
    "def add_list(web_json_obj):\n",
    "    for i in list(web_json_obj['urls'].keys()):\n",
    "        for j in list(web_json_obj['urls'][i]['sub-category'].keys()):  \n",
    "            urls = get_list_url(web_json_obj['urls'][i]['sub-category'][j]['url'])\n",
    "            print(i,j,web_json_obj['urls'][i]['sub-category'][j]['url'])\n",
    "            web_json_obj['urls'][i]['sub-category'][j]['url_list'] = filter_list(urls)\n",
    "# add post content from get content function to json object\n",
    "# add post content from get content function to json object\n",
    "def add_post(web_json_obj):\n",
    "    for i in list(web_json_obj['urls'].keys()):\n",
    "        for j in list(web_json_obj['urls'][i]['sub-category'].keys()):\n",
    "            web_json_obj['urls'][i]['sub-category'][j]['content'] = {}\n",
    "            list_key = [v for v in range(0,len(web_json_obj['urls'][i]['sub-category'][j]['url_list']))]\n",
    "            for u in list_key:\n",
    "                web_json_obj['urls'][i]['sub-category'][j]['content'][u] = {}\n",
    "                if u != \"\":\n",
    "                    web_json_obj['urls'][i]['sub-category'][j]['content'][u]['text'] ,web_json_obj['urls'][i]['sub-category'][j]['content'][u]['title'],web_json_obj['urls'][i]['sub-category'][j]['content'][u]['published_date'] = get_post(web_json_obj['urls'][i]['sub-category'][j]['url_list'][u])\n",
    "                    print(i,j,web_json_obj['urls'][i]['sub-category'][j]['cate_id'],web_json_obj['urls'][i]['sub-category'][j]['name'],web_json_obj['urls'][i]['sub-category'][j]['name'],web_json_obj['urls'][i]['sub-category'][j]['content'][u]['title'],web_json_obj['urls'][i]['sub-category'][j]['url_list'][u])\n",
    "#add all necessary information to json object\n",
    "def get_news_vtv():\n",
    "    _vtv= {\n",
    "            \"home_page\":\"https://vtv.vn/\",\n",
    "            \"urls\":{\n",
    "                \"Quần vọt\":\n",
    "                {\n",
    "                 \"url\":\"https://vtv.vn/the-thao/tennis.htm#\",\n",
    "                 \"sub-category\":{  \n",
    "                    0:{\"name\":\"Tennis\",\n",
    "                     \"url\":\"https://vtv.vn/the-thao/tennis.htm\",\n",
    "                     \"cate_id\":57,\n",
    "                      \"url_list\" : []},\n",
    "                 }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "#\n",
    "    add_list(_vtv)\n",
    "    add_post(_vtv)\n",
    "    return _vtv\n",
    "#send post content to wordpress via endpoint\n",
    "def send_post_to_5goals(title,content,category_id,published_date):\n",
    "    # URL of the API endpoint (this is a placeholder and needs to be replaced with the actual URL)\n",
    "    url = \"https://api2023.5goal.com/wp-json/custom/createPost\"\n",
    "    \n",
    "    # Data to be sent in the POST request\n",
    "    data = {\n",
    "        \"title\": title,\n",
    "        \"content\": content,\n",
    "        \"category_id\": category_id,\n",
    "        \"token\": 'draftpost',#'5goalvodichcmnl',  # Replace with your actual access token\n",
    "        \"published_date\": published_date,\n",
    "        \"domain\":\"vtv\"\n",
    "          # Replace with the actual category ID as required\n",
    "    }\n",
    "    # Sending the POST request\n",
    "    response = requests.post(url, data=data)\n",
    "    \n",
    "    # Checking the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"The post was successfully created.\")\n",
    "        print(\"Response:\", response.text)  # Prints the response text from the server\n",
    "    else:\n",
    "        print(f\"Failed to create the post. Status code: {response.status_code}\")\n",
    "def main():\n",
    "    _vtv = get_news_vtv()\n",
    "    for i in [list(_vtv['urls'].keys())[0]]:\n",
    "    #web_24h_com_vn2['url'][i]['cate_id']\n",
    "        for j in list(_vtv['urls'][i]['sub-category']):\n",
    "            url_list =  _vtv['urls'][i]['sub-category'][j]['url_list']\n",
    "            print(url_list)\n",
    "            for t in range(0,len(url_list)):\n",
    "                content = _vtv['urls'][i]['sub-category'][j]['content'][t]['text']\n",
    "                title = _vtv['urls'][i]['sub-category'][j]['content'][t]['title']\n",
    "                published_date = _vtv['urls'][i]['sub-category'][j]['content'][t]['published_date']\n",
    "                cate_id = _vtv['urls'][i]['sub-category'][j]['cate_id']\n",
    "                print(title, url_list[t],content)\n",
    "                #send_post_to_5goals(title,str(content), cate_id, published_date)\n",
    "                time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87a71400-945b-45e4-ba2e-c8d1795f27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = get_list_url('https://vtv.vn/the-thao/tennis.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf67a0b-9743-4b16-9b18-a0755a7fba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot insert None into a tag.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://vtv.vn//tennis/rafael-nadal-va-nhung-ky-vong-cho-su-tro-lai-2023120410170502.htm',\n",
       " 'https://vtv.vn//tennis/su-phat-trien-cua-cac-tay-vot-vo-dich-next-gen-atp-finals-20231204101144735.htm']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f86a3bb0-38f0-45b3-8ed2-d1d917c0739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quần vọt 0 https://vtv.vn/the-thao/tennis.htm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot insert None into a tag.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _vtv \u001b[38;5;241m=\u001b[39m get_news_vtv()\n",
      "Cell \u001b[1;32mIn[13], line 191\u001b[0m, in \u001b[0;36mget_news_vtv\u001b[1;34m()\u001b[0m\n\u001b[0;32m    175\u001b[0m     _vtv\u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome_page\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://vtv.vn/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m             }\n\u001b[0;32m    189\u001b[0m         }\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     add_list(_vtv)\n\u001b[0;32m    192\u001b[0m     add_post(_vtv)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vtv\n",
      "Cell \u001b[1;32mIn[13], line 160\u001b[0m, in \u001b[0;36madd_list\u001b[1;34m(web_json_obj)\u001b[0m\n\u001b[0;32m    158\u001b[0m urls \u001b[38;5;241m=\u001b[39m get_list_url(web_json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub-category\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,j,web_json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub-category\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 160\u001b[0m web_json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub-category\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filter_list(urls)\n",
      "Cell \u001b[1;32mIn[13], line 144\u001b[0m, in \u001b[0;36mfilter_list\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(urls)):\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         published_date \u001b[38;5;241m=\u001b[39m get_content_vtv(urls[i])[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    145\u001b[0m         date_posted_norm \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(published_date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ( (date_posted_norm\u001b[38;5;241m.\u001b[39mday \u001b[38;5;241m==\u001b[39m crawl_time\u001b[38;5;241m.\u001b[39mday) \u001b[38;5;129;01mand\u001b[39;00m (date_posted_norm\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m==\u001b[39m crawl_time\u001b[38;5;241m.\u001b[39mmonth) \u001b[38;5;129;01mand\u001b[39;00m (date_posted_norm\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m crawl_time\u001b[38;5;241m.\u001b[39myear) ):\n",
      "Cell \u001b[1;32mIn[13], line 93\u001b[0m, in \u001b[0;36mget_content_vtv\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# add avatar photo on top\u001b[39;00m\n\u001b[0;32m     92\u001b[0m first_photo \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews-avatar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m article\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, first_photo)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# centering the image\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m article\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bs4\\element.py:416\u001b[0m, in \u001b[0;36mPageElement.insert\u001b[1;34m(self, position, new_child)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Insert a new PageElement in the list of this PageElement's children.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \n\u001b[0;32m    409\u001b[0m \u001b[38;5;124;03mThis works the same way as `list.insert`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m:param new_child: A PageElement.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot insert None into a tag.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot insert a tag into itself.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot insert None into a tag."
     ]
    }
   ],
   "source": [
    "_vtv = get_news_vtv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c789df25-b628-4e82-a888-187147722405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_page': 'https://vtv.vn/',\n",
       " 'urls': {'Quần vọt': {'url': 'https://vtv.vn/the-thao/tennis.htm#',\n",
       "   'sub-category': {0: {'name': 'Tennis',\n",
       "     'url': 'https://vtv.vn/the-thao/tennis.htm',\n",
       "     'cate_id': 57,\n",
       "     'url_list': [],\n",
       "     'content': {}}}}}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_vtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802eb626-d783-44cd-9571-b4884006befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_list_url('https://vtv.vn/the-thao/tennis.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1267bdc8-cf69-4f60-8479-ca5fb5a0bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_content_vtv('https://vtv.vn/tennis/su-phat-trien-cua-cac-tay-vot-vo-dich-next-gen-atp-finals-20231204101144735.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9654727e-054d-4017-8264-96e4d8f2b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://vtv.vn//tennis/rafael-nadal-va-nhung-ky-vong-cho-su-tro-lai-2023120410170502.htm',\n",
       " 'https://vtv.vn//tennis/su-phat-trien-cua-cac-tay-vot-vo-dich-next-gen-atp-finals-20231204101144735.htm',\n",
       " 'https://vtv.vn//tennis/hamad-medjedovic-vo-dich-giai-quan-vot-next-gen-atp-finals-2023-20231203145837429.htm',\n",
       " 'https://vtv.vn//tennis/arthur-fils-va-hamad-medjekovic-vao-chung-ket-atp-next-gen-finals-2023-20231202105645614.htm',\n",
       " 'https://vtv.vn//tennis/luca-van-assche-co-tran-thang-thu-2-tai-next-gen-atp-finals-20231201095034892.htm',\n",
       " 'https://vtv.vn//tennis/siet-chat-thoi-gian-giao-bong-tai-atp-next-gen-finals-20231128071727421.htm',\n",
       " 'https://vtv.vn//tennis/hanh-trinh-dang-nho-cua-jannik-sinner-tai-davis-cup-2023-20231128043933467.htm',\n",
       " 'https://vtv.vn//tennis/tong-giai-thuong-next-gen-atp-finals-len-toi-2-trieu-usd-20231128035205244.htm',\n",
       " 'https://vtv.vn//tennis/dt-italia-lan-thu-2-vo-dich-davis-cup-20231127075101317.htm',\n",
       " 'https://vtv.vn//tennis/dt-australia-vao-chung-ket-davis-cup-2023-20231125091910805.htm',\n",
       " 'https://vtv.vn//tennis/cac-tay-vot-hang-dau-viet-nam-se-tham-du-giai-dien-dan-tennis-mien-bac-mo-rong-20231123173331597.htm',\n",
       " 'https://vtv.vn//tennis/xac-dinh-nhung-tay-vot-tham-du-atp-next-gen-finals-2023112209020896.htm',\n",
       " 'https://vtv.vn//tennis/nam-2023-thi-dau-thanh-cong-cua-novak-djokovic-20231121091234342.htm']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d47b8f-09f3-4481-ab35-c64dcaf8d037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 12, 4, 0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(test[2], '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6255b04-3538-4d27-ba94-8286975628e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 12, 4, 0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_datetime_obj('Cập nhật 10:11 ngày 04/12/2023')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20c1b26a-5f0f-4883-800b-62f63cdd285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list(urls):\n",
    "    filtered_urls = []\n",
    "    crawl_time = datetime.fromtimestamp(time.time()-0*24*3600)\n",
    "    for i in range(0,len(urls)):\n",
    "        try:\n",
    "            published_date = get_content_vtv(urls[i])[2]\n",
    "            date_posted_norm = datetime.strptime(published_date,'%Y-%m-%d')\n",
    "            if ( (date_posted_norm.day == crawl_time.day) and (date_posted_norm.month == crawl_time.month) and (date_posted_norm.year == crawl_time.year) ):\n",
    "                filtered_urls.append(urls[i])\n",
    "                #print(i)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return filtered_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355dd42-3a22-4596-844f-bf49fc607c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f07e95-47e8-4f3f-b3ac-49d0f3756a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3809aa53-302f-4ff3-827a-0d186d94f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_datetime_obj('2023-12-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d44df42-6f2a-4f87-a019-1d674c702e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://vtv.vn/tennis/rafael-nadal-va-nhung-ky-vong-cho-su-tro-lai-2023120410170502.htm')\n",
    "time.sleep(3)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "title = soup.find('h1').text.strip()\n",
    "date = soup.find('p', class_ = 'news-info').text.strip()\n",
    "published_date = get_datetime_obj(date)[1]\n",
    "first_paragraph = soup.find('h2', class_  = 'sapo')\n",
    "article = soup.find('div', id = 'entry-body')\n",
    "#strong_tag = soup.new_tag('strong') \n",
    "#strong_tag.string = first_paragraph.text # Set the content of <i> tag\n",
    "# Insert the new element as the first child\n",
    "article.insert(0, first_paragraph)\n",
    "\n",
    "for script_or_style in article(['script', 'style','iframe','video',]):\n",
    "            script_or_style.decompose()\n",
    "\n",
    "caption_text_list = article.find_all('div', class_ ='PhotoCMS_Caption')\n",
    "tags_to_remove = article.find_all(['a', 'span'])\n",
    "for tag in tags_to_remove:\n",
    "    # Extract the text from the tag\n",
    "    tag_text = tag.get_text()\n",
    "    # Replace the tag with its text content\n",
    "    tag.replace_with(tag_text)\n",
    "    tag.text.strip()\n",
    "#remove all image attributes except somes from list\n",
    "list_attr = ['src','alt','data-original']\n",
    "for i in article.find_all('img'):\n",
    "    for j in list(i.attrs.keys()):\n",
    "        if j not in list_attr:\n",
    "            i.attrs.pop(j)\n",
    "img_list = article.find_all('img')\n",
    "n_img = len(img_list)\n",
    "for i in range(0,n_img):\n",
    "       \n",
    "    caption_start = NavigableString(\"[caption id=\\\"\\\" align=\\\"aligncenter\\\" width=\\\"800\\\"]\")\n",
    "    try:\n",
    "        caption_text = NavigableString(caption_text_list[i].find('p').get_text())\n",
    "    except (IndexError,AttributeError):\n",
    "        continue\n",
    "    caption_end = NavigableString(\"[/caption]\")\n",
    "    # Insert the custom tags and caption text around the <img> tag\n",
    "    img_list[i].insert_before(caption_start)\n",
    "    img_list[i].insert_after(caption_end)\n",
    "    img_list[i].insert_after(caption_text) \n",
    "for i in article.find_all('img'):\n",
    "    try:\n",
    "        i['src'] = i['data-src']\n",
    "    except KeyError:\n",
    "        continue\n",
    "for i in caption_text_list:\n",
    "    i.decompose()\n",
    "# add avatar photo on top\n",
    "first_photo = soup.find('img', class_ = 'news-avatar')\n",
    "article.insert(0, first_photo)\n",
    "# centering the image\n",
    "for i in article.find_all('img'):\n",
    "    i['class'] = \"aligncenter\"\n",
    "    #i['width'] = 800\n",
    "   # i['height'] = 400\n",
    "    del i['data-src']\n",
    "list_attr = ['src','alt','data-ogiginal','class']\n",
    "for i in article.find_all(recursive = True):\n",
    "    for j in list(i.attrs.keys()):\n",
    "        if j not in list_attr:\n",
    "            i.attrs.pop(j)\n",
    "#remove empty div or empty space from element\n",
    "for item in article.find_all('div'):\n",
    "    if item.string ==\"\":\n",
    "        item.decompose()\n",
    "for element in article.find_all(recursive = True,string=True):\n",
    "    if isinstance(element, NavigableString) and element.strip() == '':\n",
    "        element.extract()\n",
    "#remove html comment from element   \n",
    "article.find_all('p',recursive = True)[-1].decompose()\n",
    "for comment in article.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "    comment.extract()\n",
    "\n",
    "#article.find_all(recursive = True)[-1].decompose()\n",
    "#article.find('div', class_ ='width_common box-tinlienquanv2').decompose()\n",
    "source_tag = soup.new_tag('i') \n",
    "source_tag.string = \"Nguồn: vtv.vn\"  # Set the content of <i> tag\n",
    "article.append(source_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f282c683-942f-45d5-a079-17b0d711faad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_detail ta-justify\" id=\"entry-body\"><img alt=\"\" class=\"aligncenter\" src=\"https://vtv1.mediacdn.vn/thumb_w/650/562122370168008704/2023/12/4/photo1701659799800-17016597999901359880287.jpg\"/><h2 class=\"sapo\">\n",
       "                        VTV.vn - Sự kiện quần vợt được nhắc tới nhiều trong tuần qua chính là thông báo về sự trở lại của Rafael Nadal. Cựu số 1 thế giới đã nhận được nhiều kỳ vọng với kế hoạch tương lai.\n",
       "                    </h2><p>Rafael Nadal xác nhận sẽ thi đấu ở giải quần vợt Brisbane mở rộng từ 31/12/2023 đến 7/1/2024. Đây là giải đấu đầu tiên của anh kể từ sau khi dừng bước tại vòng 2 Australia mở rộng 2023 do chấn thương cơ thắt lưng.<br/></p><p>Việc Rafael Nadal trở lại cũng nhận được sự quan tâm từ các đồng nghiệp. Tay vợt Taylor Fritz cho rằng: \"Tôi nghĩ giờ chưa phải là lúc anh ấy nghĩ tới việc giải nghệ. Nadal vẫn còn thời gian thi đấu thêm nhiều năm và việc anh ấy trở lại rõ ràng là tin tốt cho mọi người. Tôi không nghĩ quá nhiều nếu phải so tài với anh ấy. Có lẽ sẽ là 1 trận đấu không dễ dàng. Anh ấy luôn là vậy, rất mạnh mẽ trong mọi thời điểm và không dễ bỏ cuộc\".</p><div class=\"VCSortableInPreviewMode active noCaption\"><div><img alt=\"Rafael Nadal và những kỳ vọng cho sự trở lại - Ảnh 1.\" class=\"aligncenter\" src=\"https://vtv1.mediacdn.vn/thumb_w/640/562122370168008704/2023/12/4/photo-1-17016597908321283545801.jpg\"/></div></div><p>Nếu Rafael Nadal cảm thấy ổn, anh sẽ tiếp tục đăng ký thi đấu tại Australia mở rộng và gần như chắc chắn sẽ không phải thi đấu từ vòng loại, mà sẽ nhận được suất đặc cách. Ở tuổi 37, tay vợt người Tây Ban Nha vẫn còn những mục tiêu cụ thể, ngoài việc tham dự các giải Grand Slam. Đó là thêm 1 lần nữa góp mặt tại đấu trường Olympic. Năm tới, Olympic sẽ diễn ra tại Paris và môn quần vợt sẽ thi đấu trên mặt sân đất nện sở trường của anh - nơi tay vợt người Tây Ban Nha chắc chắn sẽ nhận được rất nhiều sự cổ vũ từ khán giả.</p><i>Nguồn: vtv.vn</i></div>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c9bc24-cfca-413a-bf9b-94ef27aacf36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_list\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_list' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850aa32a-8ccc-4da5-b6f4-e77cd4ff10dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
